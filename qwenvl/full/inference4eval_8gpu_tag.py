#!/usr/bin/env python
# coding=utf-8

import argparse
import csv
import os
import re
import torch
import torch.multiprocessing as mp
from tqdm import tqdm
from transformers import AutoProcessor, Qwen2_5_VLForConditionalGeneration
from qwen_vl_utils import process_vision_info
import time
from concurrent.futures import ThreadPoolExecutor
import queue

# è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•ä¸ºspawnï¼Œè§£å†³CUDAå¤šè¿›ç¨‹é—®é¢˜
mp.set_start_method('spawn', force=True)

# è®¾ç½®PyTorchä¼˜åŒ–
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False

def load_model_on_gpu(gpu_id: int, model_name: str):
    """åœ¨æŒ‡å®šGPUä¸ŠåŠ è½½æ¨¡å‹"""
    torch.cuda.set_device(gpu_id)
    print(f"ğŸ”„ GPU {gpu_id}: æ­£åœ¨åŠ è½½æ¨¡å‹...")
    
    # ä½¿ç”¨åŸå§‹QwenVLæ¨¡å‹è·¯å¾„åŠ è½½processorï¼ˆæ— è¯è¡¨æ‰©å±•ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹processorï¼‰
    checkpoint_path = "/apdcephfs_gy2/share_302507476/xiaodayang/SpatialLogic/ckpt/qwenvl/full/tag_only_good/checkpoint-24000"
    original_model_path = "/apdcephfs_gy2/share_302507476/xiaodayang/SpatialLogic/ckpt/qwenvl/original/Qwen2.5-VL-7B-Instruct"
    
    processor = AutoProcessor.from_pretrained(original_model_path, use_fast=False)
    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
        checkpoint_path,
        device_map=f"cuda:{gpu_id}",
        torch_dtype=torch.bfloat16,
        use_cache=True
    )
    model.eval()
    
    print(f"âœ… GPU {gpu_id}: æ¨¡å‹å’ŒprocessoråŠ è½½å®Œæˆ (processor: åŸå§‹QwenVL, model: checkpoint)")
    return processor, model

def infer_on_gpu(processor, model, messages: list, max_new_tokens: int, num_beams: int, gpu_id: int):
    """åœ¨æŒ‡å®šGPUä¸Šè¿›è¡Œæ¨ç†"""
    torch.cuda.set_device(gpu_id)
    
    with torch.inference_mode():
        # è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥messagesç»“æ„
        print(f"ğŸ” GPU {gpu_id}: æ£€æŸ¥messagesç»“æ„")
        for i, msg in enumerate(messages):
            print(f"  Message {i}: {msg}")
            if 'content' in msg:
                for j, content in enumerate(msg['content']):
                    print(f"    Content {j}: {content}")
        
        # æå–å›¾åƒå’Œè§†é¢‘è¾“å…¥
        image_inputs, video_inputs = process_vision_info(messages)
        print(f"ğŸ” GPU {gpu_id}: process_vision_infoè¿”å› - image_inputs: {type(image_inputs)}, video_inputs: {type(video_inputs)}")

        # æ„å»º chat prompt
        chat_prompt = processor.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        print(f"ğŸ” GPU {gpu_id}: apply_chat_templateè¿”å› - chat_prompt: {type(chat_prompt)}, é•¿åº¦: {len(chat_prompt) if chat_prompt else 'None'}")
        
        chat_prompt = chat_prompt + "\nassistant\n"

        # æ„é€  inputs - æ·»åŠ è¯¦ç»†è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ” GPU {gpu_id}: å‡†å¤‡è°ƒç”¨processor")
        print(f"  - chat_promptç±»å‹: {type(chat_prompt)}, é•¿åº¦: {len(chat_prompt) if chat_prompt else 'None'}")
        print(f"  - image_inputsç±»å‹: {type(image_inputs)}, é•¿åº¦: {len(image_inputs) if image_inputs else 'None'}")
        print(f"  - video_inputsç±»å‹: {type(video_inputs)}")
        
        # æ£€æŸ¥chat_promptä¸­æ˜¯å¦æœ‰Noneå€¼
        if chat_prompt:
            for i, char in enumerate(chat_prompt):
                if char is None:
                    print(f"âŒ GPU {gpu_id}: chat_promptä½ç½®{i}å‘ç°Noneå€¼")
                    break
        
        inputs = processor(
            text=[chat_prompt],
            images=image_inputs,
            videos=video_inputs,
            padding=True,
            return_tensors="pt"
        )
        
        # ç§»åŠ¨åˆ°æŒ‡å®šGPU
        inputs = {k: v.to(f"cuda:{gpu_id}") for k, v in inputs.items()}

        # ç”Ÿæˆ
        generated_ids = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            num_beams=num_beams,
            use_cache=True,
            pad_token_id=processor.tokenizer.pad_token_id,
            eos_token_id=processor.tokenizer.eos_token_id,
            do_sample=False,
            temperature=None,
            top_p=None,
            repetition_penalty=None
        )
        
        # è§£ç ï¼ˆä¿ç•™ç‰¹æ®Šæ ‡è®°ï¼Œé¿å…<answer>æ ‡ç­¾è¢«è¿‡æ»¤ï¼‰
        generated_text = processor.batch_decode(
            generated_ids, skip_special_tokens=False
        )[0]
        
        # æå– assistant éƒ¨åˆ†
        answer = generated_text.split("assistant")[-1].strip()
        return answer

def worker_process(gpu_id: int, task_queue: mp.Queue, result_queue: mp.Queue, model_name: str, max_new_tokens: int, num_beams: int, base_dir: str):
    """å·¥ä½œè¿›ç¨‹å‡½æ•°"""
    try:
        # åœ¨æŒ‡å®šGPUä¸ŠåŠ è½½æ¨¡å‹
        processor, model = load_model_on_gpu(gpu_id, model_name)
        
        while True:
            try:
                # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
                task = task_queue.get(timeout=1)
                if task is None:  # ç»“æŸä¿¡å·
                    break
                
                row_idx, row = task
                
                # å¤„ç†è·¯å¾„ï¼Œæ·»åŠ Noneå€¼æ£€æŸ¥
                video_path1_raw = row.get("video_path1", "")
                video_path2_raw = row.get("video_path2", "")
                task_name = row.get("task_name", "")
                
                # æ£€æŸ¥Noneå€¼
                if video_path1_raw is None or video_path2_raw is None or task_name is None:
                    print(f"âš ï¸ GPU {gpu_id} è¡Œ{row_idx}: å‘ç°Noneå€¼ - video_path1: {video_path1_raw}, video_path2: {video_path2_raw}, task_name: {task_name}")
                    continue
                
                video_path1 = video_path1_raw.strip().replace('_/','./')
                video_path2 = video_path2_raw.strip().replace('_/','./')
                task_name = task_name.strip()
                
                # æ‹¼æ¥å®Œæ•´è·¯å¾„
                video_path1 = os.path.join(base_dir, video_path1)
                video_path2 = os.path.join(base_dir, video_path2)
                
                # æ„å»ºpromptï¼ˆç®€åŒ–ä¸ºåªè¾“å‡ºæœ€ç»ˆç­”æ¡ˆï¼Œä¸éœ€è¦spatial detailsï¼‰
                prompt = (
                    f"ä½ æ˜¯ä¸€ä½ç©ºé—´æ„ŸçŸ¥ä¸“å®¶ã€‚\nè¯·ä»”ç»†è§‚å¯Ÿä¸¤å¼ å›¾ç‰‡(img1å’Œimg2)ã€‚ æç¤º: è¿™ä¸¤å¼ å›¾ç‰‡å‘ç”Ÿåœ¨åŒä¸€ä¸ªä»»åŠ¡ä¸­ï¼Œæè¿°äº†ä¸åŒçš„ä»»åŠ¡å®ŒæˆçŠ¶æ€ã€‚\nä»»åŠ¡åç§°: {task_name}\nè¯·ä½ ç›´æ¥ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚\nè¾“å‡ºæ ¼å¼:\ncloser to completion: [img1/img2]"
                )

                # è°ƒè¯•ï¼šæ£€æŸ¥è·¯å¾„å’Œpromptæ˜¯å¦æœ‰Noneå€¼
                print(f"ğŸ” GPU {gpu_id} è¡Œ{row_idx}: æ£€æŸ¥æ•°æ®")
                print(f"  - video_path1: {video_path1} (ç±»å‹: {type(video_path1)})")
                print(f"  - video_path2: {video_path2} (ç±»å‹: {type(video_path2)})")
                print(f"  - prompt: {prompt[:100]}... (ç±»å‹: {type(prompt)}, é•¿åº¦: {len(prompt) if prompt else 'None'})")
                
                messages = [{
                    "role": "user",
                    "content": [
                        {"type": "image", "image": video_path1, "image_id": "img1"},
                        {"type": "image", "image": video_path2, "image_id": "img2"},
                        {"type": "text", "text": prompt}
                    ]
                }]

                # æ¨ç†
                start_time = time.time()
                answer_text = infer_on_gpu(
                    processor, model, messages, max_new_tokens, num_beams, gpu_id
                )
                inference_time = time.time() - start_time
                print(f"\nğŸ“ GPU {gpu_id} è¡Œ{row_idx} åŸå§‹è¾“å‡º:\n{answer_text}\n")
                
                # è§£æç­”æ¡ˆï¼ˆç»Ÿä¸€æ ¼å¼ï¼šspatial details: ... å’Œ closer to completion: <answer>...</answer>ï¼‰
                spatial_details_val = ""
                closer_val = ""
                img1_text = ""
                img2_text = ""

                text_raw = answer_text
                sd_tag = "spatial details:"
                cc_tag = "closer to completion:"

                # è§£æ spatial details
                sd_idx = text_raw.find(sd_tag)
                if sd_idx != -1:
                    sd_start = sd_idx + len(sd_tag)
                    cc_idx = text_raw.find(cc_tag, sd_start)
                    if cc_idx != -1:
                        spatial_details_val = text_raw[sd_start:cc_idx].strip()
                    else:
                        spatial_details_val = text_raw[sd_start:].strip()

                # è§£æ closer to completionï¼ˆç›´æ¥è§£ææ–‡æœ¬å†…å®¹ï¼Œä¸å†æœ‰<answer>æ ‡ç­¾ï¼‰
                cc_idx2 = text_raw.find(cc_tag)
                if cc_idx2 != -1:
                    cc_start = cc_idx2 + len(cc_tag)
                    closer_val_raw = text_raw[cc_start:].strip()
                    
                    # ç›´æ¥è§£ææ–‡æœ¬å†…å®¹
                    if closer_val_raw:
                        lower = closer_val_raw.lower()
                        if "img1" in lower:
                            closer_val = "img1"
                        elif "img2" in lower:
                            closer_val = "img2"
                        else:
                            closer_val = closer_val_raw

                # å›é€€è§£æï¼ˆæ­£åˆ™ï¼Œå…¼å®¹å¤šè¡Œã€å¤§å°å†™ï¼‰
                if not spatial_details_val or not closer_val:
                    norm = text_raw
                    m_sd = re.search(r"spatial\s*details\s*:\s*(.*?)\s*(?:closer\s+to\s+completion\s*:|$)", norm, flags=re.IGNORECASE|re.DOTALL)
                    if not spatial_details_val and m_sd:
                        spatial_details_val = m_sd.group(1).strip()
                    m_cc = re.search(r"closer\s+to\s+completion\s*:\s*(.*)$", norm, flags=re.IGNORECASE|re.DOTALL)
                    if not closer_val and m_cc:
                        closer_val_raw = m_cc.group(1).strip()
                        # ç›´æ¥è§£ææ–‡æœ¬å†…å®¹ï¼ˆä¸å†æœ‰<answer>æ ‡ç­¾ï¼‰
                        if closer_val_raw:
                            low = closer_val_raw.lower()
                            if "img1" in low:
                                closer_val = "img1"
                            elif "img2" in low:
                                closer_val = "img2"
                            else:
                                closer_val = closer_val_raw

                # ä»spatial_detailsä¸­è¿›ä¸€æ­¥æ‹†åˆ†img1/img2æ®µ
                if spatial_details_val:
                    m_pair = re.search(r"img1\s*:\s*(.*?)\n\s*img2\s*:\s*(.*)", spatial_details_val, flags=re.IGNORECASE|re.DOTALL)
                    if m_pair:
                        img1_text = m_pair.group(1).strip()
                        img2_text = m_pair.group(2).strip()
                    else:
                        # å°è¯•ä»…æœ‰img1æˆ–img2çš„å•æ®µå½¢å¼
                        m1 = re.search(r"img1\s*:\s*(.*)$", spatial_details_val, flags=re.IGNORECASE|re.DOTALL)
                        m2 = re.search(r"img2\s*:\s*(.*)$", spatial_details_val, flags=re.IGNORECASE|re.DOTALL)
                        if m1:
                            img1_text = m1.group(1).strip()
                        if m2:
                            img2_text = m2.group(1).strip()

                result_item = {
                    "row_idx": row_idx,
                    "video_path1": video_path1,
                    "video_path2": video_path2,
                    "task_name": task_name,
                    "spatial_details": spatial_details_val,
                    "target": closer_val,
                    "inference_time": inference_time,
                    "gpu_id": gpu_id
                }
                
                result_queue.put(result_item)
                
            except queue.Empty:
                continue
                
    except Exception as e:
        print(f"âŒ GPU {gpu_id} å·¥ä½œè¿›ç¨‹å‡ºé”™: {e}")
        result_queue.put({"error": f"GPU {gpu_id}: {e}"})

def main():
    parser = argparse.ArgumentParser(description="Qwen2.5-VL 8å¡å¹¶è¡Œæ¨ç†")
    parser.add_argument("--model_name", type=str, default="Qwen/Qwen2.5-VL-7B-Instruct")
    parser.add_argument("--gt_csv", type=str, default="/apdcephfs_gy2/share_302507476/xiaodayang/SpatialLogic/eval/gt.csv")
    parser.add_argument("--pred_csv", type=str, default="/apdcephfs_gy2/share_302507476/xiaodayang/SpatialLogic/eval/tagger_8gpu_24000.csv")
    parser.add_argument("--base_dir", type=str, default="/apdcephfs_gy2/share_302507476/xiaodayang/SpatialLogic/data/clips")
    parser.add_argument("--max_new_tokens", type=int, default=500)
    parser.add_argument("--num_beams", type=int, default=1)
    parser.add_argument("--num_gpus", type=int, default=8, help="ä½¿ç”¨çš„GPUæ•°é‡")
    args = parser.parse_args()

    # æ£€æŸ¥GPUæ•°é‡
    if torch.cuda.device_count() < args.num_gpus:
        print(f"âš ï¸ å¯ç”¨GPUæ•°é‡ ({torch.cuda.device_count()}) å°‘äºè¯·æ±‚æ•°é‡ ({args.num_gpus})")
        args.num_gpus = torch.cuda.device_count()
    
    print(f"ğŸš€ ä½¿ç”¨ {args.num_gpus} å¼ GPUè¿›è¡Œå¹¶è¡Œæ¨ç†")
    
    # è¯»å–æ•°æ®
    print("ğŸ“Š æ­£åœ¨è¯»å–æ•°æ®...")
    with open(args.gt_csv, "r", newline="", encoding="utf-8") as f_in:
        reader = csv.DictReader(f_in)
        raw_fieldnames = reader.fieldnames or []
        fieldnames = [name.strip().lstrip("\ufeff") for name in raw_fieldnames]
        reader.fieldnames = fieldnames
        required_cols = {"video_path1", "video_path2", "task_name", "spatial_details", "target"}
        missing = required_cols - set(fieldnames)
        if missing:
            raise ValueError(f"gt.csv ç¼ºå°‘å¿…è¦åˆ—: {missing}")

        all_rows = list(reader)
        total_rows = len(all_rows)
        print(f"ğŸ“ æ€»å…± {total_rows} è¡Œæ•°æ®")

    # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—å’Œç»“æœé˜Ÿåˆ—
    task_queue = mp.Queue()
    result_queue = mp.Queue()
    
    # å¡«å……ä»»åŠ¡é˜Ÿåˆ—
    for i, row in enumerate(all_rows):
        task_queue.put((i, row))
    
    # æ·»åŠ ç»“æŸä¿¡å·
    for _ in range(args.num_gpus):
        task_queue.put(None)
    
    # å¯åŠ¨å·¥ä½œè¿›ç¨‹
    print("ğŸ”„ æ­£åœ¨å¯åŠ¨GPUå·¥ä½œè¿›ç¨‹...")
    processes = []
    for gpu_id in range(args.num_gpus):
        p = mp.Process(
            target=worker_process,
            args=(gpu_id, task_queue, result_queue, args.model_name, args.max_new_tokens, args.num_beams, args.base_dir)
        )
        p.start()
        processes.append(p)
    
    # æ”¶é›†ç»“æœ
    print("ğŸš€ å¼€å§‹å¹¶è¡Œæ¨ç†...")
    results = [None] * total_rows
    completed = 0
    
    with tqdm(total=total_rows, desc="æ¨ç†è¿›åº¦") as pbar:
        while completed < total_rows:
            try:
                result = result_queue.get(timeout=1)
                if "error" in result:
                    print(f"âŒ {result['error']}")
                    continue
                
                row_idx = result["row_idx"]
                results[row_idx] = result
                completed += 1
                pbar.update(1)
                
                # æ˜¾ç¤ºè¿›åº¦
                if completed % 10 == 0:
                    avg_time = sum(r["inference_time"] for r in results if r is not None) / completed
                    pbar.set_postfix({
                        "å®Œæˆ": f"{completed}/{total_rows}",
                        "å¹³å‡æ—¶é—´": f"{avg_time:.2f}s",
                        "GPU": f"{result['gpu_id']}"
                    })
                    
            except queue.Empty:
                continue
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    for p in processes:
        p.join()
    
    # ä¿å­˜ç»“æœ
    print("ğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœ...")
    with open(args.pred_csv, "w", newline="", encoding="utf-8") as f_out:
        fieldnames = ["video_path1", "video_path2", "task_name", "spatial_details", "target"]
        writer = csv.DictWriter(f_out, fieldnames=fieldnames)
        writer.writeheader()
        for item in results:
            if item:
                writer.writerow({
                    "video_path1": item["video_path1"],
                    "video_path2": item["video_path2"],
                    "task_name": item["task_name"],
                    "spatial_details": item["spatial_details"],
                    "target": item["target"]
                })
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_time = sum(r["inference_time"] for r in results if r is not None)
    avg_time = total_time / total_rows
    
    print(f"\nğŸ‰ æ¨ç†å®Œæˆ!")
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {total_rows}")
    print(f"â±ï¸ æ€»æ¨ç†æ—¶é—´: {total_time:.2f}s")
    print(f"âš¡ å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.2f}s/æ ·æœ¬")
    print(f"ğŸš€ 8å¡åŠ é€Ÿæ¯”: {40/avg_time:.1f}x")  # å‡è®¾åŸæ¥40s/æ ·æœ¬
    print(f"ğŸ’¾ ç»“æœä¿å­˜åˆ°: {args.pred_csv}")

if __name__ == "__main__":
    main()
